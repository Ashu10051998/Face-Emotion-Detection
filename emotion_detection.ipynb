{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "emotion detection.ipynb",
      "provenance": [],
      "mount_file_id": "195vCnRfH1rP9E-VlOK7TtG0MlI02FmiY",
      "authorship_tag": "ABX9TyNJqywuIE1o3VbMN67/pZ4J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ashu10051998/Face-Emotion-Detection/blob/main/emotion_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHXewK1r45s0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUm1_ZS85B83",
        "outputId": "0533eeaa-4973-4961-cffc-0e01e2d03026"
      },
      "source": [
        "!wget https://www.dropbox.com/s/si11cws2pyho1bp/archive.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-22 03:42:55--  https://www.dropbox.com/s/si11cws2pyho1bp/archive.zip\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.18, 2620:100:6016:18::a27d:112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/si11cws2pyho1bp/archive.zip [following]\n",
            "--2021-09-22 03:42:55--  https://www.dropbox.com/s/raw/si11cws2pyho1bp/archive.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc8f16331d9f49ed8962cb3caf13.dl.dropboxusercontent.com/cd/0/inline/BWlLIriq81Uu3A-C0snP2wnbdkVfGR0CGm_mzt6En4StLai-jo7mGPSLJjoTRuPOpZPTlHOHfSM2DApCCzxvKmghpTgrdS-y2YZOu-87klBKahphN5xIlByq7pTszEr2ph5_Rcfb5hFfd7xcix0yLiVG/file# [following]\n",
            "--2021-09-22 03:42:55--  https://uc8f16331d9f49ed8962cb3caf13.dl.dropboxusercontent.com/cd/0/inline/BWlLIriq81Uu3A-C0snP2wnbdkVfGR0CGm_mzt6En4StLai-jo7mGPSLJjoTRuPOpZPTlHOHfSM2DApCCzxvKmghpTgrdS-y2YZOu-87klBKahphN5xIlByq7pTszEr2ph5_Rcfb5hFfd7xcix0yLiVG/file\n",
            "Resolving uc8f16331d9f49ed8962cb3caf13.dl.dropboxusercontent.com (uc8f16331d9f49ed8962cb3caf13.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:6016:15::a27d:10f\n",
            "Connecting to uc8f16331d9f49ed8962cb3caf13.dl.dropboxusercontent.com (uc8f16331d9f49ed8962cb3caf13.dl.dropboxusercontent.com)|162.125.1.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/BWkQ2R6KZbwRnNKePYwSG9N78jpMQqp6Fr7JB9y3Xl9SS0d6gYWi2u6ZZUp8e5-Pq1e0zGo9JEA-5KhMP9bryuQeyvN5xX41TBGG6ZBIBujnABqZ2saCz70Aj5C4rHvTQ2ZJrj1sXfe8ToT_z7LR7MTw_sywe3fVzGMnJ21pBvfMnge_4KxOlK6nbs2rSpTiuidNN0szLxlRS2x5mZLh7fW-6ypAlpAZ9VUbalq94w7IQQj1xyg9JTQCqnYH8awz0IbL4V06R8VpztLVWXuk_IuS3ZBusoEUXtFUKR3VlIO8lXbqHGw5hWI-BJblSOiNqe9WjMEg7b-hwZythqHSM1QmWDOecTi7BqY4sNVDlCPVMt4KrAoApgRiAh_E6x1ikEU/file [following]\n",
            "--2021-09-22 03:42:55--  https://uc8f16331d9f49ed8962cb3caf13.dl.dropboxusercontent.com/cd/0/inline2/BWkQ2R6KZbwRnNKePYwSG9N78jpMQqp6Fr7JB9y3Xl9SS0d6gYWi2u6ZZUp8e5-Pq1e0zGo9JEA-5KhMP9bryuQeyvN5xX41TBGG6ZBIBujnABqZ2saCz70Aj5C4rHvTQ2ZJrj1sXfe8ToT_z7LR7MTw_sywe3fVzGMnJ21pBvfMnge_4KxOlK6nbs2rSpTiuidNN0szLxlRS2x5mZLh7fW-6ypAlpAZ9VUbalq94w7IQQj1xyg9JTQCqnYH8awz0IbL4V06R8VpztLVWXuk_IuS3ZBusoEUXtFUKR3VlIO8lXbqHGw5hWI-BJblSOiNqe9WjMEg7b-hwZythqHSM1QmWDOecTi7BqY4sNVDlCPVMt4KrAoApgRiAh_E6x1ikEU/file\n",
            "Reusing existing connection to uc8f16331d9f49ed8962cb3caf13.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 63252113 (60M) [application/zip]\n",
            "Saving to: ‘archive.zip’\n",
            "\n",
            "archive.zip         100%[===================>]  60.32M   151MB/s    in 0.4s    \n",
            "\n",
            "2021-09-22 03:42:56 (151 MB/s) - ‘archive.zip’ saved [63252113/63252113]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkZDxfkdl7-E"
      },
      "source": [
        "!unzip -q \"/content/archive.zip\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sdu8NaFvl75-"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "tf.random.set_seed(4)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIrlWpyWmubo"
      },
      "source": [
        "# Creating the Pathlib PATH objects\n",
        "train_path = Path(\"/content/train\")\n",
        "test_path = Path(\"/content/test\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWJA7O94l7wP",
        "outputId": "f3d581f4-0dfd-42eb-bf26-0ca6f96ae758"
      },
      "source": [
        "# Getting Image paths \n",
        "train_image_paths = list(train_path.glob(\"*/*\"))\n",
        "train_image_paths = list(map(lambda x : str(x) , train_image_paths))\n",
        "\n",
        "train_image_paths[:10]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/train/happy/Training_41477899.jpg',\n",
              " '/content/train/happy/Training_61706679.jpg',\n",
              " '/content/train/happy/Training_68886569.jpg',\n",
              " '/content/train/happy/Training_35728842.jpg',\n",
              " '/content/train/happy/Training_10717931.jpg',\n",
              " '/content/train/happy/Training_86039203.jpg',\n",
              " '/content/train/happy/Training_18383577.jpg',\n",
              " '/content/train/happy/Training_28198433.jpg',\n",
              " '/content/train/happy/Training_53772653.jpg',\n",
              " '/content/train/happy/Training_38756386.jpg']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeUzCUC3l7rk",
        "outputId": "5fae02f1-048a-4ea8-b34d-edc9177b40d4"
      },
      "source": [
        "# Getting their respective labels \n",
        "\n",
        "def get_label(image_path):\n",
        "    return image_path.split(\"/\")[-2]\n",
        "\n",
        "train_image_labels = list(map(lambda x : get_label(x) , train_image_paths))\n",
        "train_image_labels[:10]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['happy',\n",
              " 'happy',\n",
              " 'happy',\n",
              " 'happy',\n",
              " 'happy',\n",
              " 'happy',\n",
              " 'happy',\n",
              " 'happy',\n",
              " 'happy',\n",
              " 'happy']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KX8MJXphl7oD"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1jLE4Eol7lB",
        "outputId": "a9023763-0eb5-4c80-c96d-b42fd0137d6e"
      },
      "source": [
        "Le = LabelEncoder()\n",
        "train_image_labels = Le.fit_transform(train_image_labels)\n",
        "train_image_labels[:10]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 3, 3, 3, 3, 3, 3, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAaBncVAl7h3",
        "outputId": "de33443d-bb47-456e-e602-32c979f8cd2f"
      },
      "source": [
        "train_image_labels = tf.keras.utils.to_categorical(train_image_labels)\n",
        "\n",
        "train_image_labels[:10]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_WbEt0el7e-"
      },
      "source": [
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "Train_paths , Val_paths , Train_labels , Val_labels = train_test_split(train_image_paths , train_image_labels , test_size = 0.25)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zz9uNkRil7bD",
        "outputId": "56ed7b1e-3f13-4588-e421-2e9289b07583"
      },
      "source": [
        "classTotals = Train_labels.sum(axis=0)\n",
        "classWeight = classTotals.max() / classTotals\n",
        "\n",
        "class_weight = {e : weight for e , weight in enumerate(classWeight)}\n",
        "print(class_weight)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 1.810097, 1: 16.258259, 2: 1.7555124, 3: 1.0, 4: 1.4581201, 5: 1.5001385, 6: 2.268119}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtzrORWRl7Xg"
      },
      "source": [
        "# Function used for Transformation\n",
        "\n",
        "def load(image , label):\n",
        "    image = tf.io.read_file(image)\n",
        "    image = tf.io.decode_jpeg(image , channels = 3)\n",
        "    return image , label"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbeUVnuil7T3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClIci23ol7Qd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ug4O7Kuql7Nn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SeUgt-7l7Kb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bnMt9ALl7HT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voivyPaVl7EH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hWlO_Fel7At"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAIUH8j5l69e"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0VAmi3il66f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaxKvAuml63A"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wviXLpcl6zl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nYpZY8bl6wv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}